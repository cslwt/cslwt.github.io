
<!doctype html>
<html>

<head>
<title>Wentong Li|NUAA</title>

<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Wentong Li"> 
<meta name="description" content="Wentong Li's home page">
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />
<link rel="stylesheet" href="css/style2.css">
<!-- <link href="assets/css/bootstrap.min.css" rel="stylesheet" type="text/css"> -->
<!-- <link href="assets/css/bootstrap-responsive.min.css" rel="stylesheet" type="text/css"> -->


</head>


<body>

<div id="layout-content" style="margin-top:25px">


<table>
	<tbody>
		<tr>
			<td width="75%">
				<div id="toptitle">
					<h1>Wentong Li ÊùéÊñáÈÄö<h1>
				</div>
                 <!--
                <h3>Associate Professor</h3>
	         -->
		<p>
		 College of Artificial Intelligence 			
                </p>
		<p>
                    Nanjing University of Aeronautics and Astronautics (NUAA) </br>
		</p>
		<p>
                    NanjingÔºåChina </br>
		</p>
		<p>
			<a href="https://github.com/LiWentomng"><img src="assets/logos/github_logo.png" height="30px"></a>&nbsp;&nbsp;
			<a href="https://scholar.google.com/citations?user=MJjM6BcAAAAJ&hl=zh-CN"><img src="assets/logos/google_logo.png" height="30px"></a>&nbsp;&nbsp;
		</p>
			</td>

			</td>
			<td width="20%">
				<img src="assets/imgs/img-lwt.jpg" width="110%"/>
			</td>
		<tr>
	</tbody>
</table>


<h2><em>About Me</em></h2> 

<p style="line-height: 25px;">  
     I am an Associate Professor of the College of Artificial Intelligence at  Nanjing University of Aeronautics and Astronautics.
	
    Previously, I completed my Ph.D at College of Computer Science and Technology, Zhejiang University, fortunately supervised by Prof.
    <a href="https://person.zju.edu.cn/jkzhu">Jianke Zhu</a> and Prof.
    <a href="http://www4.comp.polyu.edu.hk/~cslzhang/">Lei Zhang </a>(PolyU, HK), in June 2024.
    My recent research interests are <i>Visual/Scene Understanding</i>, <i> Embodied AI</i> and <i>Multimodal Large Language Models</i>, particularly in:
	<br>
	<em><b> 1. Enabling MLLMs/VLMs with common visual tasks</b></em>, including visual referring and grounding for image/video/3D scene. 
	<br>
	<em><b> 2. Embodied scene understanding&reasoning</b></em>, including ego-centric image/video analysis, reasoning and interaction, scene navigation. 
	<br>
	<em><b> 3. Efficient and effective MLLMs</b></em>, including token reduction, lightweight mllm, efficient high-resolution understanding. 
	<br>
	
	Before, I mainly focus on the field of the techniques for object detection, image segmentaion and their weakly-supervised/label-efficient approaches.  Besides, I am also interested in autonomous driving tasks (HD-Map, 3D-Occupancy, etc.) and 3D reconstruction tasks.
    </p> 
</p>



<h2><em>News</em></h2> 
<ul>
     <li>
        [2025.2]: Five papers are accepted by <b>CVPR 2025</b>.
    </li>
     <li>
        [2025.2]: We released the <a href="https://huggingface.co/datasets/DAMO-NLP-SG/VideoRefer-700K">VideoRefer-700K dataset</a> on HuggingFace. Please see the <a href="https://github.com/DAMO-NLP-SG/VideoRefer">VideoRefer Suite</a> for the details.
    </li>
    <li>
        [2024.12]: Won Outstanding Doctoral Dissertation Award of ZJU (ÊµôÊ±üÂ§ßÂ≠¶‰ºòÁßÄÂçöÂ£´Â≠¶‰ΩçËÆ∫Êñá).
    </li>
    <li>
        [2024.6]: Obtained my Ph.D. degree from ZJU.
    </li>
</ul>

						
<p id="publications">
<h2><em>Preprints</em></h2>
</p>

						
<div id="pubs"></div>
    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-top:10px;margin-bottom:10px;padding-left:3px;">
          <img src="assets/imgs/tokenpacker.jpg" width="210" class="img-bordered" alt="photo">
      </div>
      <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">
         TokenPacker: Efficient Visual Projector for Multimodal LLM
      </div>
      <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
        <b>Wentong Li*</b>, Yuqian Yuan*, Jian Liu, Dongqi Tang, Song Wang, Jie Qin, Jianke Zhu, Lei Zhang
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
        ArXiv:2407.02392, 2024
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
          <a href="https://arxiv.org/abs/2407.02392" target="_blank" rel="noopener">Paper</a> ÔΩú
          <a href="https://github.com/CircleRadon/TokenPacker" target="_blank" rel="noopener">Code</a> 
          <img src="https://img.shields.io/github/stars/CircleRadon/TokenPacker?style=social" /> ÔΩú
	  <a href="https://huggingface.co/collections/sunshine-lwt/tokenpacker-66a234618f0d2327e0cf2cb1" target="_blank" rel="noopener">HuggingFace Model</a> | 
	   <a href="https://zhuanlan.zhihu.com/p/707021763" target="_blank" rel="noopener">‰∏≠ÊñáËß£ËØª</a>  ÔΩú
	   <a href="https://huggingface.co/papers?date=2024-07-04" target="_blank" rel="noopener">Daily Papers</a> 
          </p>
      </div>
</div>
					


<div id="pubs"></div>
    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-top:10px;margin-bottom:10px;padding-left:3px;">
          <img src="assets/imgs/ReliOCC.png" width="210" class="img-bordered" alt="photo">
      </div>
      <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">
           ReliOcc: Towards Reliable Semantic Occupancy Prediction via Uncertainty Learning
      </div>
      <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
        Song Wang, Zhongdao Wang, Jiawei Yu, <b>Wentong Li</b>, Bailan Feng, Junbo Chen, Jianke Zhu
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
        ArXiv:2409.18026, 2024
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
          <a href="https://arxiv.org/pdf/2409.18026" target="_blank" rel="noopener">Paper</a> 
          </p>
      </div>
</div>
						
						
<p id="publications">
<h2><em>Selected Publications</em></h2>
</p>


<div id="pubs"></div>
    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-top:10px;margin-bottom:10px;padding-left:3px;">
          <img src="assets/imgs/Inst3d-lmm.png" width="210" class="img-bordered" alt="photo">
      </div>
      <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">
         Inst3D-LMM: Instance-Aware 3D Scene Understanding with Multi-modal Instruction Tuning üî•
      </div>
      <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
	Hanxun Yu*, <b>Wentong Li*</b>, Song Wang,  Junbo Chen, Jianke Zhu
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
        CVPR, 2025 (<b>Rating Score:5/5/4</b>)
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
          <a href="https://www.arxiv.org/abs/2503.00513" target="_blank" rel="noopener">Paper</a> ÔΩú
          <a href="https://github.com/hanxunyu/Inst3D-LMM" target="_blank" rel="noopener">Code</a> 
          <img src="https://img.shields.io/github/stars/hanxunyu/Inst3D-LMM?style=social" /> 
          </p>
      </div>
</div>

						

<div id="pubs"></div>
    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-top:10px;margin-bottom:10px;padding-left:3px;">
          <img src="assets/imgs/videorefer.gif" width="210" class="img-bordered" alt="photo">
      </div>
      <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">
         VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM üî•
      </div>
      <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
	Yuqian Yuan, Hang Zhang, <b>Wentong Li</b>, Zesen Cheng, Boqiang Zhang, Long Li, Xin Li, Deli Zhao, Wenqiao Zhang, Yueting Zhuang, Jianke Zhu, Lidong Bing
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
        CVPR, 2025
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
          <a href="https://arxiv.org/abs/2501.00599" target="_blank" rel="noopener">Paper</a> ÔΩú
          <a href="https://github.com/DAMO-NLP-SG/VideoRefer" target="_blank" rel="noopener">Code</a> 
          <img src="https://img.shields.io/github/stars/DAMO-NLP-SG/VideoRefer?style=social" /> ÔΩú
	   <a href="https://huggingface.co/DAMO-NLP-SG/VideoRefer-7B" target="_blank" rel="noopener">HuggingFace Model</a> |
	   <a href="https://huggingface.co/datasets/DAMO-NLP-SG/VideoRefer-700K" target="_blank" rel="noopener">Dataset</a> |
	   <a href="https://huggingface.co/datasets/DAMO-NLP-SG/VideoRefer-Bench" target="_blank" rel="noopener">VideoRefer-Bench</a> |
	   <a href="https://huggingface.co/papers" target="_blank" rel="noopener">Daily Papers</a> 
          </p>
      </div>
</div>

						

<div id="pubs"></div>
    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-top:10px;margin-bottom:10px;padding-left:3px;">
          <img src="assets/imgs/qyqx.gif" width="200" class="img-bordered" alt="photo">
      </div>
      <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">
         Osprey: Pixel Understanding with Visual Instruction Tuning
      </div>
      <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
         Yuqian Yuan*, <b>Wentong Li*</b>, Jian Liu, Dongqi Tang, Xinjie Luo, Chi Qin, Lei Zhang, Jianke Zhu
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
        CVPR, 2024 (<b>Project Leader</b>)
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://arxiv.org/pdf/2312.10032.pdf" target="_blank" rel="noopener">Paper</a> ÔΩú
           <a href="https://github.com/CircleRadon/Osprey" target="_blank" rel="noopener">Code</a>  
	  <img src="https://img.shields.io/github/stars/CircleRadon/Osprey?style=social" /> ÔΩú
	   <a href="http://111.0.123.204:8000/" target="_blank" rel="noopener">Online Demo</a> ÔΩú
           <a href="https://www.youtube.com/watch?v=YsxqHBBnDfk" target="_blank" rel="noopener">Video Demo</a> ÔΩú
	   <a href="https://zhuanlan.zhihu.com/p/673647000" target="_blank" rel="noopener">‰∏≠ÊñáËß£ËØª</a> |
	   <a href="https://www.bilibili.com/video/BV185411q7Du/" target="_blank" rel="noopener">ËßÜÈ¢ëËß£ËØª</a> 
          </p>
      </div>
</div>

									
<div id="pubs"></div>
      <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:10px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/boxinst.gif" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Box2Mask: Box-supervised Instance Segmentation via Level-set Evolution
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            <b>Wentong Li</b>, Wenyu Liu, Jianke Zhu, Miaomiao Cui, Risheng Yu, Xiansheng Hua, Lei Zhang
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            T-PAMI, 2024
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
          <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10423160" target="_blank" rel="noopener">Paper</a> |
           <a href="https://github.com/LiWentomng/BoxInstSeg" target="_blank" rel="noopener">Code(BoxInstSeg)</a>
	  <img src="https://img.shields.io/github/stars/LiWentomng/BoxInstSeg?style=social" /> ÔΩú
          <a href="https://github.com/LiWentomng/boxlevelset" target="_blank" rel="noopener">Code(MMDet)</a>
	  <img src="https://img.shields.io/github/stars/LiWentomng/boxlevelset?style=social" />
          </p>
      </div>
      </div>
					
    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-top:10px;margin-bottom:10px;padding-left:3px;">
          <img src="assets/imgs/apro.gif" width="200" class="img-bordered" alt="photo">
      </div>
      <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">
        Label-efficient Segmentation via Affinity Propagation
      </div>
      <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
        <b>Wentong Li*</b>, Yuqian Yuan*, Song Wang, Wenyu Liu, Dongqi Tang, Jian Liu, Jianke Zhu, Lei Zhang
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
        NeurIPS, 2023
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://arxiv.org/pdf/2310.10533.pdf" target="_blank" rel="noopener">Paper</a> ÔΩú
           <a href="https://github.com/CircleRadon/APro" target="_blank" rel="noopener">Code</a>
	  <img src="https://img.shields.io/github/stars/CircleRadon/APro?style=social" /> ÔΩú
	   <a href="https://liwentomng.github.io/apro/" target="_blank" rel="noopener">Project Page</a> |
          <a href="https://zhuanlan.zhihu.com/p/674018681" target="_blank" rel="noopener">‰∏≠ÊñáËß£ËØª</a>
          </p>
      </div>
    </div>
           
           
    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-top:7px;margin-bottom:10px;padding-left:3px;">
          <img src="assets/imgs/point2mask.png" width="200" class="img-bordered" alt="photo">
      </div>
      <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
          Point2Mask: Point-supervised Panoptic Segmentation via Optimal Transport
      </div>
      <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
        <b>Wentong Li</b>, Yuqian Yuan, Song Wang, Jianke Zhu, Jianshu Li, Jian Liu, Lei Zhang
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          ICCV, 2023
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
        <p>
         <a href="https://arxiv.org/abs/2308.01779" target="_blank" rel="noopener">Paper</a> |
        <a href="https://github.com/LiWentomng/Point2Mask" target="_blank" rel="noopener">Code</a> 
	<img src="https://img.shields.io/github/stars/LiWentomng/Point2Mask?style=social" />
        </p>
    </div>
    </div>
    
    <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:10px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/boxlevelset.png" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Box-supervised Instance Segmentation with Level Set Evolution
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            <b>Wentong Li</b>, Wenyu Liu, Jianke Zhu, Miaomiao Cui, Xiansheng Hua, Lei Zhang
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            ECCV, 2022
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
          <a href="https://arxiv.org/pdf/2207.09055.pdf" target="_blank" rel="noopener">Paper</a> |
           <a href="https://github.com/LiWentomng/boxlevelset" target="_blank" rel="noopener">Code</a> 
	  <img src="https://img.shields.io/github/stars/LiWentomng/boxlevelset?style=social" />
          </p>
      </div>
      </div>

      <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:14px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/OrientedRepPoints.png" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Oriented RepPoints for Aerial Object Detection
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            <b>Wentong Li</b>, Yijie Chen, Kaixuan Hu, Jianke Zhu
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            CVPR, 2022
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Oriented_RepPoints_for_Aerial_Object_Detection_CVPR_2022_paper.pdf" target="_blank" rel="noopener">Paper</a>  | 
           <a href="https://github.com/LiWentomng/OrientedRepPoints" target="_blank" rel="noopener">Code(MMDet)</a> 
	   <img src="https://img.shields.io/github/stars/LiWentomng/OrientedRepPoints?style=social" /> | 
           <a href="https://github.com/open-mmlab/mmrotate" target="_blank" rel="noopener"> Code(MMRotate)</a> 
	  <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />  
          </p>
      </div>
      </div>
<!--
      <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:18px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/MOD-YOLT.png" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Multi-scale Object Detection in Satellite Imagery Based on YOLT
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            <b>Wentong Li</b>, Wanyi Li, Feng Yang, Peng Wang
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            IGARSS, 2019
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
          [<a href="https://www.researchgate.net/profile/Wanyi-Li-7/publication/337504245_Multi-Scale_Object_Detection_in_Satellite_Imagery_Based_On_YOLT/links/5e781c2ca6fdcccd62191490/Multi-Scale-Object-Detection-in-Satellite-Imagery-Based-On-YOLT.pdf" target="_blank" rel="noopener">paper</a>]
          </p>
      </div>
      </div>
-->


    <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:9px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/demo-scribble2scene.gif" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Label-efficient Semantic Scene Completion with Scribble Annotations
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
          Song Wang, Jiawei Yu, <b>Wentong Li</b>, Hao Shi, Kailun Yang, Junbo Chen, Jianke Zhu
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            IJCAI, 2024
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://arxiv.org/pdf/2405.15170" target="_blank" rel="noopener">Paper</a>  |
           <a href="https://github.com/songw-zju/Scribble2Scene" target="_blank" rel="noopener">Code</a>  
	  <img src="https://img.shields.io/github/stars/songw-zju/Scribble2Scene?style=social" />
          </p>
      </div>
      </div>



						
    <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:9px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/mgmap-demo2.gif" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            MGMap: Mask-Guided Learning for Online Vectorized HD Map Construction
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
          Xiaolu Liu, Song Wang, <b>Wentong Li</b>, Ruizi Yang, Junbo Chen, Jianke Zhu
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            CVPR, 2024
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://arxiv.org/pdf/2404.00876.pdf" target="_blank" rel="noopener">Paper</a>  |
           <a href="https://github.com/xiaolul2/MGMap" target="_blank" rel="noopener">Code</a>  
	  <img src="https://img.shields.io/github/stars/xiaolul2/MGMap?style=social" />
          </p>
      </div>
      </div>
					
    <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:9px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/HASSC-1.jpg" width="200" class="img-bordered" alt="photo">
        </div>

        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Not All Voxels Are Equal: Hardness-Aware Semantic Scene Completion with Self-Distillation
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
          Song Wang, Jiawei Yu, <b>Wentong Li</b>, Wenyu Liu, Junbo Chen, Jianke Zhu
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            CVPR, 2024
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://arxiv.org/pdf/2404.11958.pdf" target="_blank" rel="noopener">Paper</a> ÔΩú
         <a href="https://github.com/songw-zju/HASSC" target="_blank" rel="noopener">Code</a>  
	  <img src="https://img.shields.io/github/stars/songw-zju/HASSC?style=social" />
          </p>
      </div>
      </div>

    <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:8px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/demo-hand.gif" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Fine-Grained Multi-View Hand Reconstruction Using Inverse Rendering
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            Qiqun Gan, <b>Wentong Li</b>, Jinwei Ren, Jianke Zhu
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            AAAI, 2024
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://ojs.aaai.org/index.php/AAAI/article/view/27946" target="_blank" rel="noopener">Paper</a>ÔΩú
           <a href="https://github.com/agnJason/FMHR" target="_blank" rel="noopener">Code</a> 
	<img src="https://img.shields.io/github/stars/agnJason/FMHR?style=social" />	  
          </p>
      </div>
      </div>

    <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:5px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/H2RBox.png" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            H2RBox: Horizontal Box Annotation is All You Need for Oriented Object Detection
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            Xue Yang, Gefan Zhang, <b>Wentong Li</b>, Xuehui Wang, Yue Zhou, Junchi Yan
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            ICLR, 2023
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://arxiv.org/pdf/2210.06742v5.pdf" target="_blank" rel="noopener">Paper</a>  ÔΩú 
           <a href="https://github.com/yangxue0827/h2rbox-mmrotate" target="_blank" rel="noopener">Code(MMRotate)</a> 
		  <img src="https://img.shields.io/github/stars/yangxue0827/h2rbox-mmrotate?style=social" /> ÔΩú
          <a href="https://github.com/yangxue0827/h2rbox-jittor" target="_blank" rel="noopener">Code(Jittor)</a> 
		  <img src="https://img.shields.io/github/stars/yangxue0827/h2rbox-jittor?style=social" /> ÔΩú
	    <a href="https://zhuanlan.zhihu.com/p/574337609" target="_blank" rel="noopener">‰∏≠ÊñáËß£ËØª</a> |
	    <a href="https://www.bilibili.com/video/BV1GD4y1g7s8/" target="_blank" rel="noopener">ËßÜÈ¢ëËß£ËØª</a> 
          </p>
      </div>
      </div>

    <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:19px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/Lidar2map.png" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            LiDAR2Map: In Defense of LiDAR-Based Semantic Map Construction Using Online Camera Distillation
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
          Song Wang, <b>Wentong Li</b>, Wenyu Liu, Xiaolu Liu, Jianke Zhu
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            CVPR, 2023
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://arxiv.org/abs/2304.11379.pdf" target="_blank" rel="noopener">Paper</a>  ÔΩú
           <a href="https://github.com/songw-zju/LiDAR2Map" target="_blank" rel="noopener">Code</a>  
		  <img src="https://img.shields.io/github/stars/songw-zju/LiDAR2Map?style=social" /> 
          </p>
      </div>
      </div>

						
<!--
    <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:8px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/IA-Seg.jpg" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Improving Nighttime Driving-Scene Segmentation via Dual Image-adaptive Learnable Filters
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            Wenyu Liu, <b>Wentong Li</b>, Jianke Zhu, Miaomiao Cui, Xuansong Xie, Lei Zhang
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            T-CSVT, 2023
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
          [<a href="http://www4.comp.polyu.edu.hk/~cslzhang/paper/IA_Seg_2023.pdf" target="_blank" rel="noopener">paper</a>]
          [<a href="https://github.com/wenyyu/IA-Seg" target="_blank" rel="noopener">code</a>]
          </p>
      </div>
      </div>

      <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:15px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/facade.jpg" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Translational Symmetry-Aware Facade Parsing for 3-D Building Reconstruction
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            Hantang Liu, <b>Wentong Li</b>, Jianke Zhu
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            IEEE MultiMedia, 2022
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
          [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9849000" target="_blank" rel="noopener">paper</a>]
          </p>
      </div>
      </div>
-->


      

<!-- </ul> -->
</script>


</script>

<script>var scroll = new SmoothScroll('a[href*="#"]', {speed: 1000});</script>


<h2><em>Honors</em></h2>

<ul>
   <li>
       Outstanding Doctoral Dissertation Award of Zhejiang University, 2024
    </li> 
    <li>
        Outstanding Graduate of Zhejiang Province, 2024
    </li>
    <li>
        Outstanding Graduate of Zhejiang University, 2024
    </li>
    <li>
        Tencent Scholarship, 2023
    </li>
    <li>
        Five-A Postgraduate Student, 2023
    </li>
    <li>
        Outstanding Postgraduate Student, 2020-2023
    </li>
    <li>
        Longhu Scholarship, 2022
    </li>
    <li>
        First-class Academic Scholarship, 2018-2023
    </li>
    <li>
        National Scholarship, 2016
    </li>
</ul>





<h2> <em>Research Intern</em> </h2>	

<ul>
    <li>
        <a href="https://www.antgroup.com/">AntGroup</a > | HangZhou | Dec.2022 - Sep.2024 </br> 
        Topic: MLLM, Token Compression, Weakly-supervise Learning </br>
	Collaborator: <a href="https://openreview.net/profile?id=~Jian_liu8">Jian Liu</a >, <a href="https://openreview.net/profile?id=~Dongqi_Tang2">Dongqi Tang</a >, <a href="https://sites.google.com/view/li-js">Jianshu Li</a >
    </li>
    <li>
        <a href="https://damo.alibaba.com/?lang=zh">Alibaba DAMO Academy</a > | HangZhou | July.2020 - Oct.2020 </br>
         Topic: Oriented Object Detection, Image Segmentation </br>
	Supervisor: Prof. <a href="http://www4.comp.polyu.edu.hk/~cslzhang/">Lei Zhang </a>
    </li>
    <li>
        <a href="http://english.ia.cas.cn/">Institution of Automation, CAS </a> | Beijing | July.2018 - June.2019 </br>
         Topic: Object Detection, Remote Sensing Image </br>
	Supervisor: Prof.<a href="https://people.ucas.edu.cn/~wangpengcasia"> Peng Wang </a>, Prof.<a href="https://ia.cas.cn/rcdw/fyjy/202404/t20240422_7129916.html"> Wanyi Li </a>
    </li>
</ul>



<h2><em>Academic Services</em></h2>

<ul>
    <li>
        Conference Reviewer:</br> 
	AAAI2025, ICLR2025, CVPR2025, ICML2025 </br>
        CVPR2024, ICLR2024, ICML2024, ECCV2024, ACM MM2024, NeurIPS2024 </br>
	CVPR2023, ICCV2023, NeurIPS2023, ACM MM2023 </br>
    </li>
    <li>
        Journal Reviewer: </br>
	Transactions on Pattern Analysis and Machine Intelligence (TPAMI) </br>
	International Journal of Computer Vision (IJCV) </br>
        Transactions on Circuits and Systems for Video Technology (TCSVT) </br>
	Transactions on Multimedia (TMM) </br>
        Transactions on Geoscience and Remote Sensing (TGRS) </br>
	Pattern Recognition (PR) </br>
	ACM Computing Surveys </br>
        ISPRS Journal of Photogrammetry and Remote Sensing (P&RS) </br>
        Neurcomputing </br>
    </li>
</ul>


<h2><em>Tech. Talks</em></h2>
<ul>
	 <li>
            <em>Fine-grained Image Understanding with MLLMs</em>, ECNU, <a href="https://github.com/vpx-ecnu">Visual Perception+X(VPX) Group</a>, 2024/09.
         </li>
	 <li>
             <em>Osprey:Pixel Understanding with Visual Instruction Tuning</em>, <a href="https://www.bilibili.com/video/BV185411q7Du/">Video</a>, <a href="https://github.com/cslwt/cslwt.github.io/blob/main/assets/imgs/Osprey-slides.pdf">slides</a>, AI TIME, 2024/01.
         </li>
	 <li>
             <em> Point-supervised Image Segmentation</em>, AntGroup, Machine Intelligence Group, 2023/09.
         </li>
</ul>						

<h2><em>Teaching Assistant</em></h2>

<ul>
    <li>
        Teaching Assistant, Police Brain of Zhejiang Province, <em>Image Processing and Analysis</em>,  Fall 2022.
    </li>
    <li>
        Teaching Assistant, Zhejiang University, FDS2021: <em>Foundation of Data Structure</em>, Fall 2021.
    </li>
</ul>




<table width="100%"> 
	<tr> 
		<td align="center">&copy; Wentong Li | Last update: Mar. 2025</td>
	</tr> 
</table>

</div>


</body>

</html>

