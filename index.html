
<!doctype html>
<html>

<head>
<title>Wentong Li|ZJU</title>

<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Wentong Li"> 
<meta name="description" content="Wentong Li's home page">
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />
<link rel="stylesheet" href="css/style2.css">
<!-- <link href="assets/css/bootstrap.min.css" rel="stylesheet" type="text/css"> -->
<!-- <link href="assets/css/bootstrap-responsive.min.css" rel="stylesheet" type="text/css"> -->


</head>


<body>

<div id="layout-content" style="margin-top:25px">


<table>
	<tbody>
		<tr>
			<td width="75%">
				<div id="toptitle">
					<h1>Wentong Li ÊùéÊñáÈÄö<h1>
				</div>

                <h3>PhD</h3>

		<p>
                    Zhejiang University </br>
                    Email: liwentong@zju.edu.cn </br>
		</p>
		<p>
			<a href="https://github.com/LiWentomng"><img src="assets/logos/github_logo.png" height="30px"></a>&nbsp;&nbsp;
			<a href="https://scholar.google.com/citations?user=MJjM6BcAAAAJ&hl=zh-CN"><img src="assets/logos/google_logo.png" height="30px"></a>&nbsp;&nbsp;
		</p>
			</td>

			</td>
			<td width="20%">
				<img src="assets/imgs/person-img.jpg" width="110%"/>
			</td>
		<tr>
	</tbody>
</table>


<h2><em>About Me</em></h2> 

<p style="line-height: 25px;">
    I did my Ph.D at College of Computer Science and Technology, Zhejiang University, fortunately supervised by Prof.
    <a href="https://person.zju.edu.cn/jkzhu">Jianke Zhu</a> and Prof.
    <a href="http://www4.comp.polyu.edu.hk/~cslzhang/">Lei Zhang </a>(PolyU, HK).
    My recent research interests are <b>visual understanding</b>b> and <b>multimodal large language models</b>b>, particularly in:
	<br>
	<i> 1. Enabling MLLMs with downstream vision tasks</i>, including visual referring and grounding for image/video/3D scene. 
	
	<br>
	<i> 2. Efficient and effective MLLMs </i>, including token reduction, lightweight mllm, efficient high-resolution understanding. 
	<br>
	
	Before, I mainly focus on the field of the techniques for object detection, image segmentaion and their weakly-supervised/label-efficient approaches.  Besides, I am also interested in autonomous driving tasks (HD-Map, 3D-Occupancy, etc.) and 3D reconstruction tasks.
    </p> 
</p>


<!--
<h2><i>News</i>üî•</h2> 

<ul>
    <li>
        02/2024: Three papers on MLLM (Osprey), HD-Map, 3D-Occupancy are accepted by CVPR2024. 
    </li>
    <li>
        01/2024: Our work(Box2Mask) is accepted by IEEE T-PAMI.
    </li>
</ul>
-->
						
<p id="publications">
<h2><em>Preprints</em></h2>
</p>

<div id="pubs"></div>
    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-top:10px;margin-bottom:10px;padding-left:3px;">
          <img src="assets/imgs/tokenpacker.jpg" width="210" class="img-bordered" alt="photo">
      </div>
      <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">
         TokenPacker: Efficient Visual Projector for Multimodal LLM
      </div>
      <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
        <b>Wentong Li*</b>, Yuqian Yuan*, Jian Liu, Dongqi Tang, Song Wang, Jie Qin, Jianke Zhu, Lei Zhang, 
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
        ArXiv:2407.02392, 2024
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
          <a href="https://arxiv.org/abs/2407.02392" target="_blank" rel="noopener">Paper</a> ÔΩú
          <a href="https://github.com/CircleRadon/TokenPacker" target="_blank" rel="noopener">Code</a> 
          <img src="https://img.shields.io/github/stars/CircleRadon/TokenPacker?style=social" /> ÔΩú
	   <a href="https://zhuanlan.zhihu.com/p/707021763" target="_blank" rel="noopener">‰∏≠ÊñáËß£ËØª</a>  ÔΩú
	   <a href="https://huggingface.co/papers?date=2024-07-04" target="_blank" rel="noopener">Daily Papers</a> 
          </p>
      </div>
</div>

						
						

<p id="publications">
<h2><em>Selected Publications</em></h2>
</p>


<div id="pubs"></div>
    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-top:10px;margin-bottom:10px;padding-left:3px;">
          <img src="assets/imgs/qyqx.gif" width="200" class="img-bordered" alt="photo">
      </div>
      <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">
         Osprey: Pixel Understanding with Visual Instruction Tuning
      </div>
      <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
         Yuqian Yuan*, <b>Wentong Li*</b>, Jian Liu, Dongqi Tang, Xinjie Luo, Chi Qin, Lei Zhang, Jianke Zhu
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
        CVPR, 2024
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://arxiv.org/pdf/2312.10032.pdf" target="_blank" rel="noopener">Paper</a> ÔΩú
           <a href="https://github.com/CircleRadon/Osprey" target="_blank" rel="noopener">Code</a>  
	  <img src="https://img.shields.io/github/stars/CircleRadon/Osprey?style=social" /> ÔΩú
	   <a href="http://111.0.123.204:8000/" target="_blank" rel="noopener">Online Demo</a> ÔΩú
           <a href="https://www.youtube.com/watch?v=YsxqHBBnDfk" target="_blank" rel="noopener">Video Demo</a> ÔΩú
	   <a href="https://zhuanlan.zhihu.com/p/673647000" target="_blank" rel="noopener">‰∏≠ÊñáËß£ËØª</a> 
          </p>
      </div>
</div>

									
<div id="pubs"></div>
      <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:10px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/Box2Mask.png" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Box2Mask: Box-supervised Instance Segmentation via Level-set Evolution
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            <b>Wentong Li</b>, Wenyu Liu, Jianke Zhu, Miaomiao Cui, Risheng Yu, Xiansheng Hua, Lei Zhang
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            T-PAMI, 2024
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
          <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10423160" target="_blank" rel="noopener">Paper</a> |
           <a href="https://github.com/LiWentomng/BoxInstSeg" target="_blank" rel="noopener">Code(BoxInstSeg)</a>
	  <img src="https://img.shields.io/github/stars/LiWentomng/BoxInstSeg?style=social" /> ÔΩú
          <a href="https://github.com/LiWentomng/boxlevelset" target="_blank" rel="noopener">Code(MMDet)</a>
	  <img src="https://img.shields.io/github/stars/LiWentomng/boxlevelset?style=social" />
          </p>
      </div>
      </div>
					
    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-top:10px;margin-bottom:10px;padding-left:3px;">
          <img src="assets/imgs/apro.gif" width="200" class="img-bordered" alt="photo">
      </div>
      <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">
        Label-efficient Segmentation via Affinity Propagation
      </div>
      <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
        <b>Wentong Li*</b>, Yuqian Yuan*, Song Wang, Wenyu Liu, Dongqi Tang, Jian Liu, Jianke Zhu, Lei Zhang
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
        NeurIPS, 2023
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://arxiv.org/pdf/2310.10533.pdf" target="_blank" rel="noopener">Paper</a> ÔΩú
           <a href="https://github.com/CircleRadon/APro" target="_blank" rel="noopener">Code</a>
	  <img src="https://img.shields.io/github/stars/CircleRadon/APro?style=social" /> ÔΩú
	   <a href="https://liwentomng.github.io/apro/" target="_blank" rel="noopener">Project Page</a> |
          <a href="https://zhuanlan.zhihu.com/p/674018681" target="_blank" rel="noopener">‰∏≠ÊñáËß£ËØª</a>
          </p>
      </div>
    </div>
           
           
    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-top:7px;margin-bottom:10px;padding-left:3px;">
          <img src="assets/imgs/point2mask.png" width="200" class="img-bordered" alt="photo">
      </div>
      <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
          Point2Mask: Point-supervised Panoptic Segmentation via Optimal Transport
      </div>
      <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
        <b>Wentong Li</b>, Yuqian Yuan, Song Wang, Jianke Zhu, Jianshu Li, Jian Liu, Lei Zhang
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          ICCV, 2023
      </div>
      <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
        <p>
         <a href="https://arxiv.org/abs/2308.01779" target="_blank" rel="noopener">Paper</a> |
        <a href="https://github.com/LiWentomng/Point2Mask" target="_blank" rel="noopener">Code</a> 
	<img src="https://img.shields.io/github/stars/LiWentomng/Point2Mask?style=social" />
        </p>
    </div>
    </div>
    
    <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:10px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/boxlevelset.png" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Box-supervised Instance Segmentation with Level Set Evolution
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            <b>Wentong Li</b>, Wenyu Liu, Jianke Zhu, Miaomiao Cui, Xiansheng Hua, Lei Zhang
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            ECCV, 2022
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
          <a href="https://arxiv.org/pdf/2207.09055.pdf" target="_blank" rel="noopener">Paper</a> |
           <a href="https://github.com/LiWentomng/boxlevelset" target="_blank" rel="noopener">Code</a> 
	  <img src="https://img.shields.io/github/stars/LiWentomng/boxlevelset?style=social" />
          </p>
      </div>
      </div>

      <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:14px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/OrientedRepPoints.png" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Oriented RepPoints for Aerial Object Detection
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            <b>Wentong Li</b>, Yijie Chen, Kaixuan Hu, Jianke Zhu
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            CVPR, 2022
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Oriented_RepPoints_for_Aerial_Object_Detection_CVPR_2022_paper.pdf" target="_blank" rel="noopener">Paper</a>  | 
           <a href="https://github.com/LiWentomng/OrientedRepPoints" target="_blank" rel="noopener">Code(MMDet)</a> 
	   <img src="https://img.shields.io/github/stars/LiWentomng/OrientedRepPoints?style=social" /> | 
           <a href="https://github.com/open-mmlab/mmrotate" target="_blank" rel="noopener"> Code(MMRotate)</a> 
	  <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />  
          </p>
      </div>
      </div>
<!--
      <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:18px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/MOD-YOLT.png" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Multi-scale Object Detection in Satellite Imagery Based on YOLT
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            <b>Wentong Li</b>, Wanyi Li, Feng Yang, Peng Wang
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            IGARSS, 2019
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
          [<a href="https://www.researchgate.net/profile/Wanyi-Li-7/publication/337504245_Multi-Scale_Object_Detection_in_Satellite_Imagery_Based_On_YOLT/links/5e781c2ca6fdcccd62191490/Multi-Scale-Object-Detection-in-Satellite-Imagery-Based-On-YOLT.pdf" target="_blank" rel="noopener">paper</a>]
          </p>
      </div>
      </div>
-->
					
    <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:9px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/MGMap.jpg" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            MGMap: Mask-Guided Learning for Online Vectorized HD Map Construction
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
          Xiaolu Liu, Song Wang, <b>Wentong Li</b>, Ruizi Yang, Junbo Chen, Jianke Zhu
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            CVPR, 2024
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://arxiv.org/pdf/2404.00876.pdf" target="_blank" rel="noopener">Paper</a>  |
           <a href="https://github.com/xiaolul2/MGMap" target="_blank" rel="noopener">Code</a>  
	  <img src="https://img.shields.io/github/stars/xiaolul2/MGMap?style=social" />
          </p>
      </div>
      </div>
					
    <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:9px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/HASSC-1.jpg" width="200" class="img-bordered" alt="photo">
        </div>

        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Not All Voxels Are Equal: Hardness-Aware Semantic Scene Completion with Self-Distillation
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
          Song Wang, Jiawei Yu, <b>Wentong Li</b>, Wenyu Liu, Junbo Chen, Jianke Zhu
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            CVPR, 2024
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://arxiv.org/pdf/2404.11958.pdf" target="_blank" rel="noopener">Paper</a> ÔΩú
         <a href="https://github.com/songw-zju/HASSC" target="_blank" rel="noopener">Code</a>  
	  <img src="https://img.shields.io/github/stars/songw-zju/HASSC?style=social" />
          </p>
      </div>
      </div>

    <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:8px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/aaai2024-hand.jpg" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Fine-Grained Multi-View Hand Reconstruction Using Inverse Rendering
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            Qiqun Gan, <b>Wentong Li</b>, Jinwei Ren, Jianke Zhu
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            AAAI, 2024
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://ojs.aaai.org/index.php/AAAI/article/view/27946" target="_blank" rel="noopener">Paper</a>ÔΩú
           <a href="https://github.com/agnJason/FMHR" target="_blank" rel="noopener">Code</a> 
	<img src="https://img.shields.io/github/stars/agnJason/FMHR?style=social" />	  
          </p>
      </div>
      </div>

    <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:5px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/H2RBox.png" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            H2RBox: Horizontal Box Annotation is All You Need for Oriented Object Detection
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            Xue Yang, Gefan Zhang, <b>Wentong Li</b>, Xuehui Wang, Yue Zhou, Junchi Yan
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            ICLR, 2023
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://arxiv.org/pdf/2210.06742v5.pdf" target="_blank" rel="noopener">Paper</a>  ÔΩú 
           <a href="https://github.com/yangxue0827/h2rbox-mmrotate" target="_blank" rel="noopener">Code(MMRotate)</a> 
		  <img src="https://img.shields.io/github/stars/yangxue0827/h2rbox-mmrotate?style=social" /> ÔΩú
          <a href="https://github.com/yangxue0827/h2rbox-jittor" target="_blank" rel="noopener">Code(Jittor)</a> 
		  <img src="https://img.shields.io/github/stars/yangxue0827/h2rbox-jittor?style=social" /> ÔΩú
	    <a href="https://zhuanlan.zhihu.com/p/574337609" target="_blank" rel="noopener">‰∏≠ÊñáËß£ËØª</a> 	  
          </p>
      </div>
      </div>

    <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:19px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/Lidar2map.png" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            LiDAR2Map: In Defense of LiDAR-Based Semantic Map Construction Using Online Camera Distillation
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
          Song Wang, <b>Wentong Li</b>, Wenyu Liu, Xiaolu Liu, Jianke Zhu
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            CVPR, 2023
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
           <a href="https://arxiv.org/abs/2304.11379.pdf" target="_blank" rel="noopener">Paper</a>  ÔΩú
           <a href="https://github.com/songw-zju/LiDAR2Map" target="_blank" rel="noopener">Code</a>  
		  <img src="https://img.shields.io/github/stars/songw-zju/LiDAR2Map?style=social" /> 
          </p>
      </div>
      </div>

						
<!--
    <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:8px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/IA-Seg.jpg" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Improving Nighttime Driving-Scene Segmentation via Dual Image-adaptive Learnable Filters
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            Wenyu Liu, <b>Wentong Li</b>, Jianke Zhu, Miaomiao Cui, Xuansong Xie, Lei Zhang
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            T-CSVT, 2023
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
          [<a href="http://www4.comp.polyu.edu.hk/~cslzhang/paper/IA_Seg_2023.pdf" target="_blank" rel="noopener">paper</a>]
          [<a href="https://github.com/wenyyu/IA-Seg" target="_blank" rel="noopener">code</a>]
          </p>
      </div>
      </div>

      <div class="paper" style="clear:left;">
        <div class="pimg" style="float:left;margin-top:15px;margin-bottom:10px;padding-left:3px;">
            <img src="assets/imgs/facade.jpg" width="200" class="img-bordered" alt="photo">
        </div>
        <div class="ptitle" style="padding:1px;margin-left:240px;line-height:1.8">	
            Translational Symmetry-Aware Facade Parsing for 3-D Building Reconstruction
        </div>
        <div class="pauthors" style="padding:1px;margin-left:240px;line-height:1.8">
            Hantang Liu, <b>Wentong Li</b>, Jianke Zhu
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
            IEEE MultiMedia, 2022
        </div>
        <div class="pvenue" style="padding:1px;margin-left:240px;line-height:1.8">
          <p>
          [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9849000" target="_blank" rel="noopener">paper</a>]
          </p>
      </div>
      </div>
-->


      

<!-- </ul> -->
</script>


</script>

<script>var scroll = new SmoothScroll('a[href*="#"]', {speed: 1000});</script>


<h2><em>Honors</em></h2>

<ul>
    <li>
        Outstanding Graduate of Zhejiang Province, 2024
    </li>
    <li>
        Outstanding Graduate of Zhejiang University, 2024
    </li>
    <li>
        Tencent Scholarship, 2023
    </li>
    <li>
        Five-A Postgraduate Student, 2023
    </li>
    <li>
        Outstanding Postgraduate Student, 2020-2023
    </li>
    <li>
        Longhu Scholarship, 2022
    </li>
    <li>
        First-class Academic Scholarship, 2018-2023
    </li>
    <li>
        National Scholarship, 2016
    </li>
</ul>





<h2> <em>Research Intern</em> </h2>	

<ul>
    <li>
        <a href="https://www.antgroup.com/">AntGroup</a > | HangZhou | Dec.2022 - Present</br> 
        Topic: MLLM, Weakly-supervised/Label-efficient Segmentation </br>
    </li>
    <li>
        <a href="https://damo.alibaba.com/?lang=zh">DAMO Academy</a > | HangZhou | July.2020 - Oct.2020 </br>
         Topic: Oriented Object Detection, Instance Segmentation </br>
    </li>
    <li>
        <a href="http://english.ia.cas.cn/">Institution of Automation, CAS </a> | Beijing | July.2018 - June.2019 </br>
         Topic: Object Detection, Remote Sensing Image </br>
    </li>
</ul>



<h2><em>Academic Services</em></h2>

<ul>
    <li>
        Conference Reviewer:</br> 
	AAAI2025, ICLR2025 </br>
        CVPR2024, ICLR2024, ICML2024, ECCV2024, ACM MM2024, NeurIPS2024 </br>
	CVPR2023, ICCV2023, NeurIPS2023, ACM MM2023 </br>
    </li>
    <li>
        Journal Reviewer: </br>
	International Journal of Computer Vision (IJCV) </br>
        Transactions on Circuits and Systems for Video Technology (TCSVT) </br>
	Transactions on Multimedia (TMM) </br>
        Transactions on Geoscience and Remote Sensing (TGRS) </br>
	Pattern Recognition (PR) </br>
	ACM Computing Surveys </br>
        ISPRS Journal of Photogrammetry and Remote Sensing (P&RS) </br>
        Neurcomputing </br>
    </li>
</ul>


<h2><em>Tech. Talks</em></h2>
<ul>
	 <li>
             AI TIME-<a href="https://mp.weixin.qq.com/s/CGPTOFAVzh-SqduJIIFbrw">Â§ßÊ®°ÂûãÂòâÂπ¥Âçé</a>, <em>Osprey:Pixel Understanding with Visual Instruction Tuning</em>, <a href="https://www.bilibili.com/video/BV185411q7Du/">Video</a>, <a href="https://github.com/cslwt/cslwt.github.io/blob/main/assets/imgs/Osprey-slides.pdf">slides</a>, 2024/01.
         </li>
</ul>						

<h2><em>Teaching Assistant</em></h2>

<ul>
    <li>
        Teaching Assistant, Police Brain of Zhejiang Province, <em>Image Processing and Analysis</em>,  Fall 2022.
    </li>
    <li>
        Teaching Assistant, FDS2021: <em>Foundation of Data Structure</em>,  Fall 2021.
    </li>
</ul>




<table width="100%"> 
	<tr> 
		<td align="center">&copy; Wentong Li | Last update: Aug. 2024</td>
	</tr> 
</table>

</div>


</body>

</html>

